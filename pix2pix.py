import os # Dosya ve klasÃ¶r iÅŸlemleri iÃ§in (veri yÃ¼kleme vs.)
import re  # ğŸ‘ˆ Dosya isimlerinden sayÄ± Ã§ekmek iÃ§in eklendi
import torch  #PyTorch ana kÃ¼tÃ¼phane - tensÃ¶rler ve model eÄŸitimi iÃ§in
import torch.nn as nn  # Derin Ã¶ÄŸrenme katmanlarÄ±nÄ± oluÅŸturmak iÃ§in (CNN, ReLU vb.)
from torchvision import transforms  # GÃ¶rsel dÃ¶nÃ¼ÅŸÃ¼m iÅŸlemleri iÃ§in (resize, normalize vb.)
from torch.utils.data import Dataset, DataLoader # Verileri batch'leyip modele vermek iÃ§in
from PIL import Image # Verileri batch'leyip modele vermek iÃ§in

# -------------------------
# Generator
# -------------------------
class Generator(nn.Module):  #nn.Module, tÃ¼m modellerin tÃ¼rediÄŸi ana sÄ±nÄ±ftÄ±r. generator bu sÄ±nfÄ± miras alÄ±r
    def __init__(self, latent_dim=3): #rgb gÃ¶rÃ¼ntÃ¼ler iÃ§in 3 kanal 
        super(Generator, self).__init__()
        #TÃ¼m katmanlarÄ± sÄ±ralÄ± bir ÅŸekilde tanÄ±mlarÄ±z.- nn.Sequential, bir dizi katmanÄ± sÄ±rayla uygular (ileri besleme yÃ¶nÃ¼nde) 
        self.model = nn.Sequential(
            #konvÃ¼lasyon katmanÄ±
            #2D gÃ¶rÃ¼ntÃ¼ler iÃ§in konvolÃ¼syon (filtreleme) iÅŸlemi yapar
            #kernel_size=4: Filtre boyutu 4x4
            #Ä°ki pikselde bir kayarak gÃ¶rÃ¼ntÃ¼yÃ¼ yarÄ± boyuta indirir.
            nn.Conv2d(latent_dim, 64, 4, stride=2, padding=1),

            #relu aktivasyon fonksiyonudur ve negatif degerler 0 yapar, true ise belleÄŸi optimize eder
            nn.ReLU(True),

            nn.Conv2d(64, 128, 4, stride=2, padding=1),

            #Batch Normalization, Ã¶ÄŸrenmeyi hÄ±zlandÄ±rÄ±r ve denge saÄŸlar.128 kanalÄ± normalize eder
            nn.BatchNorm2d(128),

            nn.ReLU(True),

            #KonvolÃ¼syonun Tersi (TransposeConv)
            #bu katman gÃ¶rÃ¼ntÃ¼yÃ¼ yeniden bÃ¼yÃ¼tÃ¼r 
            nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(True),
            nn.ConvTranspose2d(64, 3, 4, stride=2, padding=1),

            #egitim sÄ±rasÄ±nda veriler normalize edilmistir. bu yÃ¼zden Ã§Ä±ktÄ±yÄ± Ã‡Ä±ktÄ±yÄ± [-1, 1] aralÄ±ÄŸÄ±na sÄ±kÄ±ÅŸtÄ±rÄ±r.
            nn.Tanh()
        )

    #Bu fonksiyon modelin Ã§alÄ±ÅŸmasÄ±nÄ± tanÄ±mlar.
    def forward(self, x):
        return self.model(x)

# -------------------------
# Discriminator (PatchGAN)
# -------------------------
class Discriminator(nn.Module):
    def __init__(self, in_channels=3):
        super(Discriminator, self).__init__()

        #Katman OluÅŸturucu Fonksiyon (block):Bu fonksiyon, sÄ±k tekrar edilen katmanlarÄ± oluÅŸturmak iÃ§in tanÄ±mlanmÄ±ÅŸ mini bir fonksiyondur.
        #LeakyReLU: Aktivasyon fonksiyonu. Negatif deÄŸerleri sÄ±fÄ±rlamak yerine kÃ¼Ã§Ã¼k bir oranda geÃ§irir (0.2).
        def block(in_filters, out_filters, normalize=True):
            layers = [nn.Conv2d(in_filters, out_filters, 4, stride=2, padding=1)]
            if normalize:
                layers.append(nn.BatchNorm2d(out_filters))
            layers.append(nn.LeakyReLU(0.2, inplace=True))
            return layers #Bu fonksiyon bir liste dÃ¶ndÃ¼rÃ¼r: Bu katmanlar tek baÅŸÄ±na kullanÄ±lmaz. Genellikle nn.Sequential(*block(...)) ÅŸeklinde birleÅŸtirilerek bir modelin parÃ§asÄ± yapÄ±lÄ±r.

        self.model = nn.Sequential(
            #Girdi olarak hem orijinal resim hem de Ã§Ä±ktÄ± resim (gerÃ§ek ya da sahte) veriyoruz.bu yÃ¼zden Ã§arpÄ± 2
             #Yani: 3 kanal (girdi) + 3 kanal (Ã§Ä±ktÄ±) = 6 kanal
             #Ä°lk katman: Normalize edilmez (genelde ilk katmanda yapÄ±lmaz).
             #Girdi: 6 kanal â†’ Ã‡Ä±ktÄ±: 64 kanal
             #GÃ¶rsel boyutu kÃ¼Ã§Ã¼lÃ¼r.
            *block(in_channels * 2, 64, normalize=False),

            #64 â†’ 128 kanala Ã§Ä±kar. Normalize edilir.
            *block(64, 128),

            #128 â†’ 256 kanal
            *block(128, 256),
            *block(256, 512),

             #512 kanal â†’ 1 kanallÄ± sonuÃ§ haritasÄ± Ã¼retir.
            #Bu Ã§Ä±ktÄ±, her bÃ¶lgenin "gerÃ§ek mi sahte mi" olduÄŸuna dair tahminidir.
            #Bu yaklaÅŸÄ±ma PatchGAN denir: GÃ¶rselin tamamÄ± yerine kÃ¼Ã§Ã¼k parÃ§alar deÄŸerlendirilir.
            nn.Conv2d(512, 1, 4, padding=1)
        )



    #img_A: Girdi gÃ¶rseli
    #img_B: Ã‡izim gÃ¶rseli (gerÃ§ek ya da Ã¼retilmiÅŸ)
    #torch.cat((img_A, img_B), 1): Bu iki resmi kanal boyutunda birleÅŸtirir (Ã¶rneÄŸin 3+3 = 6 kanal olur)
    #self.model(x): Bu birleÅŸik resmi modele verir ve sonucu dÃ¶ndÃ¼rÃ¼r.
    def forward(self, img_A, img_B):
        x = torch.cat((img_A, img_B), 1)
        return self.model(x)





# -------------------------
# Ayarlar
# -------------------------
epochs = 10
batch_size = 4
img_size = 256
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# -------------------------
# Veri DÃ¶nÃ¼ÅŸtÃ¼rme ve YÃ¼kleme
# -------------------------
#Bu, gÃ¶rseli modele vermeden Ã¶nce nasÄ±l iÅŸleyeceÄŸimizi tanÄ±mlar.
transform = transforms.Compose([
    transforms.Resize((img_size, img_size)),  #reesize, GÃ¶rseli 256x256 boyutuna getirir. Ã§Ã¼nkÃ¼ yukarda Ã¶yle ayarlamÄ±stÄ±k
    transforms.ToTensor() #tetensor PIL formatÄ±ndaki gÃ¶rseli PyTorchâ€™un anlayacaÄŸÄ± tensÃ¶r formatÄ±na Ã§evirir.AyrÄ±ca pikselleri [0, 1] arasÄ±na normalize eder.
])

# Dosya isimlerini iÃ§indeki sayÄ±ya gÃ¶re sÄ±ralamak iÃ§in
def sort_by_number(file_list):
    return sorted(file_list, key=lambda x: int(re.findall(r'\d+', x)[0]))

class PairedDataset(Dataset):
    def __init__(self, root_dir, transform=None):
        self.normal_dir = os.path.join(root_dir, "girdi")
        self.sketch_dir = os.path.join(root_dir, "cikti")
        
        self.normal_images = sort_by_number(os.listdir(self.normal_dir))  
        self.sketch_images = sort_by_number(os.listdir(self.sketch_dir))  
        
        #EÄŸer bir klasÃ¶rde fazla gÃ¶rÃ¼ntÃ¼ varsa, eÅŸleÅŸmenin bozulmamasÄ± iÃ§in daha az olan kadar veri kullanÄ±lÄ±r.
        self.length = min(len(self.normal_images), len(self.sketch_images))
        self.transform = transform

    def __len__(self):
        return self.length

    def __getitem__(self, idx): #TAM YOL VERÄ°R
        normal_path = os.path.join(self.normal_dir, self.normal_images[idx])
        sketch_path = os.path.join(self.sketch_dir, self.sketch_images[idx])

        normal_image = Image.open(normal_path).convert("RGB")
        sketch_image = Image.open(sketch_path).convert("RGB")

        if self.transform:
            normal_image = self.transform(normal_image)
            sketch_image = self.transform(sketch_image)

        return normal_image, sketch_image #SonuÃ§ olarak bir (girdi, Ã§Ä±ktÄ±) Ã§ifti dÃ¶ner.


# Dosya yollarÄ± buraya gÃ¶re dÃ¼zenlenmiÅŸ:
dataset = PairedDataset(r"C:\Users\gulse\Desktop\karakalem", transform=transform)

#shuffle=True: Her epoch baÅŸÄ±nda verileri karÄ±ÅŸtÄ±rÄ±r. BÃ¶ylece model ezberlemeye meyilli olmaz.
dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

# -------------------------
# Model, optimizer ve loss
# -------------------------
#Daha Ã¶nce tanÄ±mlanan Generator ve Discriminator sÄ±nÄ±flarÄ±ndan birer model nesnesi oluÅŸturuluyor.
generator = Generator().to(device)
discriminator = Discriminator().to(device)

#Ä°ki adet optimizer (aÄŸÄ±rlÄ±klarÄ± gÃ¼ncelleyen algoritma) tanÄ±mlanÄ±yor
#Biri Generator iÃ§in (optimizer_G), diÄŸeri Discriminator iÃ§in (optimizer_D).
#Adam optimizasyon algoritmasÄ± kullanÄ±lÄ±yor.
#lr=0.0002: Ã–ÄŸrenme oranÄ± â€” aÄŸÄ±rlÄ±klarÄ±n ne kadar deÄŸiÅŸeceÄŸini belirler.
#betas=(0.5, 0.999): Adam algoritmasÄ±nÄ±n moment hesaplamalarÄ± iÃ§in sabitler (genellikle bu deÄŸerler Ã¶nerilir GAN eÄŸitimlerinde).
optimizer_G = torch.optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))
optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))

#Bu iki kayÄ±p fonksiyonu birlikte Generator'Ä± eÄŸitmekte kullanÄ±lÄ±r:

#1) adversarial_loss: Generator'Ä±n Discriminator'Ä± kandÄ±rmak iÃ§in Ã¼rettiÄŸi gÃ¶rsellerin baÅŸarÄ±sÄ±nÄ± Ã¶lÃ§er (Mean Squared Error).
#DÃ¼ÅŸÃ¼k olmasÄ± iyi generator iyi gorsel uretiyor demektir 
adversarial_loss = nn.MSELoss()


#2) pixelwise_loss: GerÃ§ek ve Ã¼retilen gÃ¶rseller arasÄ±nda piksel seviyesinde farkÄ± Ã¶lÃ§er (Mean Absolute Error / L1).
pixelwise_loss = nn.L1Loss()

# -------------------------
# EÄŸitim DÃ¶ngÃ¼sÃ¼
# -------------------------
for epoch in range(epochs):
    for i, batch in enumerate(dataloader):
        if batch is None:
            continue
        real_A, real_B = batch
        #GÃ¶rselleri modelin Ã§alÄ±ÅŸtÄ±ÄŸÄ± cihaza (CPU veya GPU) taÅŸÄ±yoruz.
        real_A = real_A.to(device)
        real_B = real_B.to(device)

        #valid: GerÃ§ek gÃ¶rsel iÃ§in etiket. TÃ¼m deÄŸerleri 1.
        #fake: Sahte (Ã¼retilmiÅŸ) gÃ¶rsel iÃ§in etiket. TÃ¼m deÄŸerleri 0.
        #Bu etiketler Discriminator'Ä±n Ã§Ä±ktÄ±larÄ±na karÅŸÄ±lÄ±k gelir.
        #1-> 1 SKOR DOÄRI YA DA YANLÄ°S
        #PatchGAN mimarisine gÃ¶re Discriminator Ã§Ä±ktÄ±sÄ±nÄ±n boyutu
        #PatchGAN GÃ¶rÃ¼ntÃ¼yÃ¼ 15x15â€™lik bir Ä±zgara (grid) gibi dÃ¼ÅŸÃ¼nÃ¼r.HER BÄ°R Ä°Ã‡Ä°N 1 YA SDA 0 SKORU OLUSTURUR
        valid = torch.ones((real_A.size(0), 1, 15, 15), requires_grad=False).to(device)
        fake = torch.zeros((real_A.size(0), 1, 15, 15), requires_grad=False).to(device)

        # Train Generator
        #Generator'Ä±n Ã¶nceki eÄŸitim adÄ±mlarÄ±ndan gelen gradyanlarÄ± sÄ±fÄ±rlÄ±yoruz
        #Bu, her eÄŸitim adÄ±mÄ±nda doÄŸru gradyanlarÄ±n hesaplanmasÄ±nÄ± saÄŸlar.
        optimizer_G.zero_grad()

        fake_B = generator(real_A) #Generator, real_A (girdi gÃ¶rÃ¼ntÃ¼sÃ¼) ile fake_B (sahte Ã§Ä±ktÄ± gÃ¶rseli) Ã¼retir.
        g_loss = adversarial_loss(discriminator(real_A, fake_B), valid) + 100 * pixelwise_loss(fake_B, real_B)
        
        #Generator kaybÄ±nÄ±n gradyanlarÄ± hesaplanÄ±r. Bu iÅŸlem, modelin aÄŸÄ±rlÄ±klarÄ±nÄ± gÃ¼ncellemek iÃ§in gereklidir.
        g_loss.backward()

        #Generator'Ä±n aÄŸÄ±rlÄ±klarÄ±, gradyanlarÄ± kullanarak gÃ¼ncellenir.
        optimizer_G.step()

        # Train Discriminator
        optimizer_D.zero_grad()

        #gerÃ§ek kaybÄ± (real_loss): GerÃ§ek gÃ¶rseller (real_A, real_B) Discriminator tarafÄ±ndan test edilir ve valid etiketiyle karÅŸÄ±laÅŸtÄ±rÄ±lÄ±r.
        #Sahte kaybÄ± (fake_loss): Generator tarafÄ±ndan Ã¼retilen sahte gÃ¶rseller (real_A, fake_B.detach()) Discriminator tarafÄ±ndan test edilir ve fake etiketiyle karÅŸÄ±laÅŸtÄ±rÄ±lÄ±r.
        #.detach() kullanÄ±lmasÄ±, sahte gÃ¶rsellerin gradyanlarÄ±nÄ±n Generatorâ€™a geri gitmesini engeller.
        real_loss = adversarial_loss(discriminator(real_A, real_B), valid)
        fake_loss = adversarial_loss(discriminator(real_A, fake_B.detach()), fake)
        d_loss = 0.5 * (real_loss + fake_loss)
        d_loss.backward()
        optimizer_D.step()

        print(f"[Epoch {epoch}/{epochs}] [Batch {i}/{len(dataloader)}] [D loss: {d_loss.item():.4f}] [G loss: {g_loss.item():.4f}]")

# Modeli kaydet
torch.save(generator.state_dict(), "generator.pth")
torch.save(discriminator.state_dict(), "discriminator.pth")
print("âœ… EÄŸitim tamamlandÄ±, modeller kaydedildi.")
